{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4 functions\n",
    "# get_advisory(list_input) : Download Advisory zip file and unzip to get shapefiles\n",
    "# gdf = read_5dayForecast(list_input): Output 5-day forecast (center location, wind speed, etc)\n",
    "# get_forwardspeed(list_input): Output forward movement direction and forward speed from text advisory\n",
    "# get_max_wind(gdf): Output max wind speed from 5day hurricane forecast\n",
    "# get_inland(gdf): Check if 5day hurricane location is inland or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: Brent Austgen - https://github.com/infra-resil/bga-work/blob/master/notebooks/download-hand-0-2-1.ipynb\n",
    "import os\n",
    "import re\n",
    "import urllib\n",
    "from multiprocessing.pool import Pool\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hurricane_Advisory:\n",
    "    def __init__(self, _id, _yr, _adv_type, _adv_num):\n",
    "        self.id = _id\n",
    "        self.yr = _yr\n",
    "        self.type = _adv_type\n",
    "        self.num = _adv_num\n",
    "        self.tide = '2'\n",
    "        \n",
    "    def get_storm(self):\n",
    "        output = '%s%s%si%s.shp' % (self.direction, str(self.category), str(self.fws), str(self.tide))\n",
    "        return output\n",
    "        \n",
    "    def get_advisory(self, working_dir): # Get hurricane advisory zip file from NOAA archive\n",
    "        hurr_id = self.id\n",
    "        hurr_yr = self.yr\n",
    "        hurr_adv_type = self.type\n",
    "        hurr_adv_num = self.num\n",
    "\n",
    "        if len(str(hurr_adv_num)) == 1:\n",
    "            hurr_adv_num = '00' + str(hurr_adv_num)\n",
    "        elif len(str(hurr_adv_num)) == 2:\n",
    "            hurr_adv_num = '0' + str(hurr_adv_num)\n",
    "        suffix = '%s%s_%s_%s' % (hurr_id, hurr_yr, hurr_adv_type, hurr_adv_num)\n",
    "        suffix_file = '%s.zip' % (suffix)\n",
    "\n",
    "        url = 'https://www.nhc.noaa.gov/gis/forecast/archive/'\n",
    "        advisory_url = url + suffix_file\n",
    "\n",
    "        # setup directory for storing data\n",
    "        data_dir = working_dir + str(hurr_yr) + '/' + hurr_id + '/' \n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "\n",
    "        # download advisory file\n",
    "        r = requests.get(advisory_url)  \n",
    "        save_location = data_dir + suffix_file\n",
    "        with open(save_location, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "        # unzip file\n",
    "        zip_file = suffix_file\n",
    "        zip_dir = suffix + '/'\n",
    "        with zipfile.ZipFile(data_dir + zip_file,\"r\") as zip_ref:\n",
    "            zip_ref.extractall(data_dir + zip_dir)\n",
    "\n",
    "    \n",
    "    def read_5dayForecast(self, working_dir):\n",
    "\n",
    "        hurr_id = self.id\n",
    "        hurr_yr = self.yr\n",
    "        hurr_adv_type = self.type\n",
    "        hurr_adv_num = self.num\n",
    "\n",
    "        if len(str(hurr_adv_num)) ==1:\n",
    "            hurr_adv_num = '00' + str(hurr_adv_num)\n",
    "        elif len(str(hurr_adv_num)) == 2:\n",
    "            hurr_adv_num = '0' + str(hurr_adv_num)\n",
    "\n",
    "        # read point data\n",
    "        shp_file_name = '%s%s-%s_%s_pts' % (hurr_id, hurr_yr, hurr_adv_num, hurr_adv_type)\n",
    "        shp_file = shp_file_name + '.shp'\n",
    "\n",
    "        data_dir = working_dir + str(hurr_yr) + '/' + hurr_id + '/' \n",
    "        suffix = '%s%s_%s_%s' % (hurr_id, hurr_yr, hurr_adv_type, hurr_adv_num)\n",
    "        shp_file_directory = suffix + '/'\n",
    "\n",
    "        # shp file location\n",
    "        output_gdf = gpd.read_file(data_dir + shp_file_directory + shp_file)\n",
    "\n",
    "        return output_gdf\n",
    "    \n",
    "    def get_max_wind(self, input_gdf):\n",
    "        dict_ws = dict(zip(input_gdf['TAU'], input_gdf['MAXWIND']))\n",
    "\n",
    "        max_ws = max(dict_ws.values()) # unit: knots\n",
    "\n",
    "        max_ws_keys = []\n",
    "        max_ws_keys_time = []\n",
    "        for key, value in dict_ws.items():\n",
    "            if value == max_ws:\n",
    "                max_ws_keys.append(key)\n",
    "                max_ws_keys_time.append(input_gdf.loc[input_gdf['TAU'] == key]['VALIDTIME'].values[0])\n",
    "\n",
    "        if max_ws < 64:\n",
    "            category = 0\n",
    "        elif (max_ws >= 64) and (max_ws < 83):\n",
    "            category = 1\n",
    "        elif (max_ws >= 83) and (max_ws < 96):\n",
    "            category = 2\n",
    "        elif (max_ws >= 96) and (max_ws < 113):\n",
    "            category = 3\n",
    "        elif (max_ws >= 113) and (max_ws < 137):\n",
    "            category = 4\n",
    "        elif max_ws >= 137: \n",
    "            category = 5\n",
    "\n",
    "        print('Max Wind(kt): %s, Category: %s, key: %s, Max Wind Hour: %s' % (max_ws, category, max_ws_keys, max_ws_keys_time))\n",
    "        \n",
    "        self.category = category\n",
    "        \n",
    "        return [max_ws, category, max_ws_keys, max_ws_keys_time]\n",
    "    \n",
    "    def get_inland(self, input_gdf):\n",
    "        # Get Texas shapefile\n",
    "        file_directory = '/Users/kyoung/Box Sync/qgis/gis/formatted/shp/'\n",
    "        file_name = 'texas.shp'\n",
    "        gdf_tx = gpd.read_file(file_directory + file_name)\n",
    "        tx_poly = gdf_tx['geometry'].values[0]\n",
    "\n",
    "        dict_center = dict(zip(input_gdf.TAU, input_gdf.geometry))\n",
    "\n",
    "        inland_hrs = []\n",
    "        for key, value in dict_center.items():\n",
    "            if value.within(tx_poly):\n",
    "                inland_hrs.append(key)\n",
    "        min_hr = min(inland_hrs)\n",
    "\n",
    "        min_hr_time = input_gdf.loc[input_gdf['TAU'] == min_hr]['VALIDTIME'].values[0]\n",
    "        \n",
    "        return [min_hr, min_hr_time]\n",
    "    \n",
    "    def get_forwardspeed(self):\n",
    "\n",
    "        hurr_id = self.id\n",
    "        hurr_yr = self.yr\n",
    "        hurr_adv_type = self.type\n",
    "        hurr_adv_num = self.num\n",
    "\n",
    "        if len(str(hurr_adv_num)) ==1:\n",
    "            hurr_adv_num = '00' + str(hurr_adv_num)\n",
    "        elif len(str(hurr_adv_num)) == 2:\n",
    "            hurr_adv_num = '0' + str(hurr_adv_num)\n",
    "\n",
    "        url = 'https://www.nhc.noaa.gov/archive/%s/%s/%s%s.fstadv.%s.shtml?' % (hurr_yr, hurr_id, hurr_id, hurr_yr, hurr_adv_num)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text_adv = soup.findAll('pre')[0]\n",
    "\n",
    "        a = str(text_adv)\n",
    "        b = a.split('\\n')\n",
    "        for i in b:\n",
    "            if 'PRESENT MOVEMENT' in i:\n",
    "                row = i\n",
    "\n",
    "        forward_speed_string = row.split(' ')\n",
    "\n",
    "        for i in range(len(forward_speed_string)):\n",
    "            if forward_speed_string[i] == 'OR':\n",
    "                position_dir = i\n",
    "            elif forward_speed_string[i] == 'KT':\n",
    "                position_fws = i\n",
    "\n",
    "        fws = forward_speed_string[position_fws-1]\n",
    "        fws_int = int(fws) * 1.15078\n",
    "        print(fws_int)\n",
    "        \n",
    "        check_speed = [5, 10, 15]\n",
    "        diff = 100\n",
    "\n",
    "        for j in check_speed:\n",
    "            temp_diff = abs(j - fws_int)\n",
    "            \n",
    "            if temp_diff < diff:\n",
    "                diff = temp_diff\n",
    "                fws_check = j    \n",
    "        \n",
    "        direction = forward_speed_string[position_dir-1]\n",
    "\n",
    "        dict_direction = {'NORTH': 'n',\n",
    "                          'NORTH-NORTHEAST' : 'nne',\n",
    "                          'NORTHEAST' : 'ne',\n",
    "                          'EAST-NORTHEAST': 'ene',\n",
    "                          'EAST': 'e',\n",
    "                          'EAST-SOUTHEAST': 'ese',\n",
    "                          'SOUTHEAST': 'se',\n",
    "                          'SOUTH-SOUTHEAST': 'sse',\n",
    "                          'SOUTH': 's',\n",
    "                          'SOUTH-SOUTHWEST': 'ssw',\n",
    "                          'SOUTHWEST': 'sw',\n",
    "                          'WEST-SOUTHWEST': 'wsw',\n",
    "                          'WEST': 'w',\n",
    "                          'WEST-NORTHWEST': 'wnw',\n",
    "                          'NORTHWEST': 'nw',\n",
    "                          'NORTH-NORTHWEST': 'nnw'}\n",
    "        \n",
    "        self.direction = dict_direction[direction]\n",
    "        self.fws = fws_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hurricane input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define working directory\n",
    "working_dir = '/Users/kyoung/Box Sync/qgis/hurricane/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First input advisory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Wind(kt): 100.0, Category: 3, key: [48.0], Max Wind Hour: ['27/0600']\n",
      "17.261699999999998\n",
      "wnw315i2.shp\n"
     ]
    }
   ],
   "source": [
    "# Input hurricane data\n",
    "hurr_id = 'al13'\n",
    "hurr_yr = 2020\n",
    "hurr_adv_type = '5day'\n",
    "hurr_adv_num = 22\n",
    "\n",
    "adv = Hurricane_Advisory(hurr_id, hurr_yr, hurr_adv_type, hurr_adv_num)\n",
    "adv.get_advisory(working_dir)\n",
    "gdf = adv.read_5dayForecast(working_dir)\n",
    "cat = adv.get_max_wind(gdf)\n",
    "adv.get_forwardspeed()\n",
    "print(adv.get_storm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second input advisory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Wind(kt): 130.0, Category: 4, key: [12.0], Max Wind Hour: ['27/0600']\n",
      "14.960139999999999\n",
      "nw415i2.shp\n"
     ]
    }
   ],
   "source": [
    "# Input hurricane data\n",
    "hurr_id = 'al13'\n",
    "hurr_yr = 2020\n",
    "hurr_adv_type = '5day'\n",
    "hurr_adv_num = 28\n",
    "\n",
    "adv = Hurricane_Advisory(hurr_id, hurr_yr, hurr_adv_type, hurr_adv_num)\n",
    "adv.get_advisory(working_dir)\n",
    "gdf = adv.read_5dayForecast(working_dir)\n",
    "cat = adv.get_max_wind(gdf)\n",
    "adv.get_forwardspeed()\n",
    "print(adv.get_storm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
